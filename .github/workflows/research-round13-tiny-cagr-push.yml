name: research-round13-tiny-cagr-push

on:
  workflow_dispatch:
    inputs:
      start_date:
        description: "Price download start date (YYYY-MM-DD)"
        required: true
        default: "2000-01-01"
      universe_config:
        description: "Universe config YAML path"
        required: true
        default: "config/universe_round12_expanded_v2.yml"
      grid_config:
        description: "Grid config YAML path"
        required: true
        default: "config/grid_round13_tiny_cagr_push.yml"
      out_dir:
        description: "Output directory"
        required: true
        default: "_out/round13_tiny_cagr_push"

jobs:
  run-grid:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install package + deps
        run: |
          python -m pip install --upgrade pip
          pip install .
          pip install pyarrow pandas pyyaml

      - name: Download prices (yfinance)
        run: |
          mkdir -p data
          python scripts/download_prices.py \
            --start "${{ inputs.start_date }}" \
            --out "data/prices.csv" \
            --tickers-from-config "${{ inputs.universe_config }}"

      - name: Run grid (round13 tiny cagr push)
        run: |
          python scripts/run_grid.py \
            --prices "data/prices.csv" \
            --config "${{ inputs.universe_config }}" \
            --grid "${{ inputs.grid_config }}" \
            --out-dir "${{ inputs.out_dir }}"

      - name: Ensure wf_results.csv exists (convert from parquet if needed)
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          OUT="${{ inputs.out_dir }}"

          if [ -f "${OUT}/wf_results.csv" ]; then
            echo "wf_results.csv already exists."
          elif [ -f "${OUT}/wf_results.parquet" ]; then
            echo "Converting wf_results.parquet -> wf_results.csv"
            python -c "import pandas as pd; df=pd.read_parquet('${OUT}/wf_results.parquet'); df.to_csv('${OUT}/wf_results.csv', index=False); print('wrote', '${OUT}/wf_results.csv', 'rows', len(df))"
          else
            echo "No wf_results.csv or wf_results.parquet found in ${OUT}"
          fi

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: round13_tiny_cagr_push_outputs
          path: |
            data/prices.csv
            ${{ inputs.out_dir }}/param_summary.csv
            ${{ inputs.out_dir }}/best_params.json
            ${{ inputs.out_dir }}/wf_results.csv
            ${{ inputs.out_dir }}/wf_results.parquet
            ${{ inputs.out_dir }}/equity.csv
            ${{ inputs.out_dir }}/equity.parquet